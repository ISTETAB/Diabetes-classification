{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:52.262678Z",
     "start_time": "2024-02-21T00:49:50.794295Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 02:49:51.015910: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-21 02:49:51.015954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-21 02:49:51.016473: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-21 02:49:51.019701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 02:49:51.495955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 02:49:52.116941: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.141826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.141878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.145105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.145149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.145169: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.258367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.258407: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.258414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-02-21 02:49:52.258436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-21 02:49:52.258450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55cb0f1640d0e79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:52.502915Z",
     "start_time": "2024-02-21T00:49:52.263840Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df = df[df['age']>=18]\n",
    "df = df[df['bmi']<=40]\n",
    "#Preprocess the data\n",
    "numeric_col=[]\n",
    "non_numeric_col=[]\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        if(df[column].nunique()<5):\n",
    "            non_numeric_col.append(column)\n",
    "        else:\n",
    "            numeric_col.append(column)\n",
    "    else:\n",
    "        non_numeric_col.append(column)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['smoking_history'] = df['smoking_history'].replace({'not current':'former','ever':'never'})\n",
    "df_copy = df.copy()\n",
    "for col in non_numeric_col:\n",
    "    df[col]=le.fit_transform(df[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee8173b7a65bc95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:52.672118Z",
     "start_time": "2024-02-21T00:49:52.668250Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y = df['diabetes']\n",
    "X = df.drop('diabetes', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0788172b85a6fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:53.187734Z",
     "start_time": "2024-02-21T00:49:53.184232Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scale_pos_weight = y.value_counts()[0] /  y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2d8dbae1b8ff36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:53.960986Z",
     "start_time": "2024-02-21T00:49:53.922788Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, stratify = y_test)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "combined_X_train = np.concatenate((X_train_scaled,X_val_scaled), axis = 0)\n",
    "combined_y_train = np.concatenate((y_train,y_val), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b34a245d8d6829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:55.095202Z",
     "start_time": "2024-02-21T00:49:55.008937Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8270ef52602d7056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:55.775204Z",
     "start_time": "2024-02-21T00:49:55.772741Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66539, 8)\n"
     ]
    }
   ],
   "source": [
    "print(combined_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6823cc7e6d4ac4fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:49:58.936515Z",
     "start_time": "2024-02-21T00:49:58.930648Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Input\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable()\n",
    "class DiabetesClassifier(Model):\n",
    "    def __init__(self, data_input, num_of_dense_layers = 3, dense_number = 8, dropout = 0, l2 = 0.001, opt_threshold = 0):\n",
    "        super(DiabetesClassifier, self).__init__()\n",
    "        self.opt_threshold = opt_threshold\n",
    "        self.num_of_dense_layers = num_of_dense_layers\n",
    "        self.dense_number = dense_number\n",
    "        self.dropout = dropout\n",
    "        self.data_input = data_input\n",
    "        self.l2 = l2\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def build_model(self):\n",
    "        inp = Input(shape = self.data_input)\n",
    "        reg = keras.regularizers.l2(self.l2)\n",
    "        x = Dense(self.data_input, activation = 'relu', kernel_regularizer=reg)(inp)\n",
    "        for i in range(self.num_of_dense_layers):\n",
    "            x = Dense(units = self.dense_number, activation = 'relu', kernel_regularizer=reg)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(self.dropout)(x)\n",
    "        output = Dense(units =1, activation = 'sigmoid')(x)\n",
    "        model = Model(inputs = inp, outputs = output)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e818d4e5dcd36b77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:50:01.371Z",
     "start_time": "2024-02-21T00:50:01.367742Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d8127f8a6b03524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:44:31.062106Z",
     "start_time": "2024-02-21T00:23:44.799738Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3109/3109 [==============================] - 64s 20ms/step - loss: 1.3005 - auc_2: 0.8605 - precision_2: 0.6198 - recall_2: 0.9667 - accuracy: 1.0053e-05 - val_loss: 0.9896 - val_auc_2: 0.9514 - val_precision_2: 0.1836 - val_recall_2: 0.9954 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "3109/3109 [==============================] - 59s 19ms/step - loss: 0.8791 - auc_2: 0.9309 - precision_2: 0.6835 - recall_2: 0.9898 - accuracy: 2.0107e-05 - val_loss: 0.8389 - val_auc_2: 0.9546 - val_precision_2: 0.1934 - val_recall_2: 0.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.7988 - auc_2: 0.9382 - precision_2: 0.7069 - recall_2: 0.9919 - accuracy: 0.0000e+00 - val_loss: 0.9485 - val_auc_2: 0.9582 - val_precision_2: 0.1931 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "3109/3109 [==============================] - 63s 20ms/step - loss: 0.7603 - auc_2: 0.9420 - precision_2: 0.7142 - recall_2: 0.9926 - accuracy: 0.0000e+00 - val_loss: 0.5805 - val_auc_2: 0.9576 - val_precision_2: 0.2452 - val_recall_2: 0.9797 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.7289 - auc_2: 0.9443 - precision_2: 0.7173 - recall_2: 0.9939 - accuracy: 7.0374e-05 - val_loss: 0.7862 - val_auc_2: 0.9622 - val_precision_2: 0.1980 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.7048 - auc_2: 0.9467 - precision_2: 0.7201 - recall_2: 0.9951 - accuracy: 4.3230e-04 - val_loss: 0.8543 - val_auc_2: 0.9628 - val_precision_2: 0.1959 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.6963 - auc_2: 0.9478 - precision_2: 0.7194 - recall_2: 0.9950 - accuracy: 5.3283e-04 - val_loss: 0.7931 - val_auc_2: 0.9645 - val_precision_2: 0.1997 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.6874 - auc_2: 0.9495 - precision_2: 0.7193 - recall_2: 0.9956 - accuracy: 9.5508e-04 - val_loss: 0.9620 - val_auc_2: 0.9629 - val_precision_2: 0.1931 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "3109/3109 [==============================] - 66s 21ms/step - loss: 0.6806 - auc_2: 0.9507 - precision_2: 0.7191 - recall_2: 0.9957 - accuracy: 0.0015 - val_loss: 0.7250 - val_auc_2: 0.9644 - val_precision_2: 0.1927 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "3109/3109 [==============================] - 61s 20ms/step - loss: 0.6721 - auc_2: 0.9523 - precision_2: 0.7229 - recall_2: 0.9954 - accuracy: 9.0481e-04 - val_loss: 0.8256 - val_auc_2: 0.9646 - val_precision_2: 0.1912 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.6691 - auc_2: 0.9525 - precision_2: 0.7222 - recall_2: 0.9957 - accuracy: 0.0012 - val_loss: 0.7819 - val_auc_2: 0.9656 - val_precision_2: 0.1996 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "3109/3109 [==============================] - 63s 20ms/step - loss: 0.6591 - auc_2: 0.9532 - precision_2: 0.7213 - recall_2: 0.9962 - accuracy: 9.7519e-04 - val_loss: 0.7151 - val_auc_2: 0.9639 - val_precision_2: 0.1978 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "3109/3109 [==============================] - 60s 19ms/step - loss: 0.6617 - auc_2: 0.9537 - precision_2: 0.7223 - recall_2: 0.9956 - accuracy: 7.9423e-04 - val_loss: 0.8731 - val_auc_2: 0.9670 - val_precision_2: 0.2013 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "3109/3109 [==============================] - 60s 19ms/step - loss: 0.6575 - auc_2: 0.9546 - precision_2: 0.7231 - recall_2: 0.9955 - accuracy: 8.4449e-04 - val_loss: 0.7700 - val_auc_2: 0.9671 - val_precision_2: 0.1993 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "3109/3109 [==============================] - 63s 20ms/step - loss: 0.6643 - auc_2: 0.9543 - precision_2: 0.7207 - recall_2: 0.9960 - accuracy: 0.0014 - val_loss: 0.7003 - val_auc_2: 0.9672 - val_precision_2: 0.2001 - val_recall_2: 0.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "3109/3109 [==============================] - 64s 21ms/step - loss: 0.6663 - auc_2: 0.9537 - precision_2: 0.7194 - recall_2: 0.9953 - accuracy: 0.0011 - val_loss: 0.8107 - val_auc_2: 0.9653 - val_precision_2: 0.2033 - val_recall_2: 0.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "3109/3109 [==============================] - 63s 20ms/step - loss: 0.6584 - auc_2: 0.9548 - precision_2: 0.7199 - recall_2: 0.9959 - accuracy: 0.0014 - val_loss: 0.7990 - val_auc_2: 0.9676 - val_precision_2: 0.1975 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.6534 - auc_2: 0.9562 - precision_2: 0.7234 - recall_2: 0.9953 - accuracy: 0.0013 - val_loss: 0.6915 - val_auc_2: 0.9673 - val_precision_2: 0.1982 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "3109/3109 [==============================] - 64s 21ms/step - loss: 0.6479 - auc_2: 0.9569 - precision_2: 0.7249 - recall_2: 0.9952 - accuracy: 0.0016 - val_loss: 0.7833 - val_auc_2: 0.9667 - val_precision_2: 0.1937 - val_recall_2: 1.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "3109/3109 [==============================] - 62s 20ms/step - loss: 0.6496 - auc_2: 0.9576 - precision_2: 0.7243 - recall_2: 0.9948 - accuracy: 0.0025 - val_loss: 0.8075 - val_auc_2: 0.9684 - val_precision_2: 0.2290 - val_recall_2: 0.9963 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe2417445b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DiabetesClassifier(X_train_scaled.shape[1], num_of_dense_layers =5, dense_number =16, dropout = 0.2, l2 = 0.001)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='logs')\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [metrics.AUC(), metrics.Precision(), metrics.Recall(), metrics.Accuracy()])\n",
    "model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), batch_size =32, epochs = 20, class_weight = {1: scale_pos_weight, 0: 1}, callbacks = [tensorboard])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd87475ee12bea6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:45:44.404495Z",
     "start_time": "2024-02-21T00:45:38.038627Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/416 [==============================] - 1s 3ms/step\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "416/416 [==============================] - 1s 3ms/step\n",
      "416/416 [==============================] - 1s 3ms/step\n",
      "416/416 [==============================] - 1s 3ms/step\n",
      "Fold 1: Optimal threshold: 0.9860290884971619, F1 Score: 0.7775131014768937\n",
      "Fold 2: Optimal threshold: 0.9865700602531433, F1 Score: 0.8\n",
      "Fold 3: Optimal threshold: 0.9863243699073792, F1 Score: 0.7822349570200574\n",
      "Fold 4: Optimal threshold: 0.9865864515304565, F1 Score: 0.7896226415094341\n",
      "Fold 5: Optimal threshold: 0.9822980165481567, F1 Score: 0.7978142076502731\n",
      "Average Optimal Threshold: 0.9855615496635437, Average F1 Score: 0.7894369815313317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "n_splits = 5  # Number of folds for StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "opt_thresholds = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in cv.split(combined_X_train, combined_y_train):\n",
    "    # Split data into training and validation for the current fold\n",
    "    X_train_curr, X_val_curr = combined_X_train[train_index], combined_X_train[val_index]\n",
    "    y_train_curr, y_val_curr = combined_y_train[train_index], combined_y_train[val_index]\n",
    "\n",
    "    # Predict probabilities for the positive class on the validation data\n",
    "    y_pred_prob = model.predict(X_val_curr).ravel()\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val_curr, y_pred_prob)\n",
    "\n",
    "    # Calculate F1 scores for each threshold\n",
    "    f1_scores_fold = [2 * (p * r) / (p + r) if (p + r) > 0 else 0 for p, r in zip(precision, recall)]\n",
    "\n",
    "    # Find the index of the maximum F1 score\n",
    "    opt_idx = np.argmax(f1_scores_fold)\n",
    "    opt_threshold = thresholds[opt_idx] if opt_idx < len(thresholds) else 1.0\n",
    "\n",
    "    # Store the optimal threshold for this fold\n",
    "    opt_thresholds.append(opt_threshold)\n",
    "    f1_scores.append(f1_scores_fold[opt_idx])\n",
    "\n",
    "# Optionally, you can print or analyze the optimal thresholds and F1 scores for each fold\n",
    "for i, (threshold, f1_score) in enumerate(zip(opt_thresholds, f1_scores)):\n",
    "    print(f\"Fold {i+1}: Optimal threshold: {threshold}, F1 Score: {f1_score}\")\n",
    "\n",
    "# You might also calculate and print the average optimal threshold and F1 score across folds if desired\n",
    "average_opt_threshold = np.mean(opt_thresholds)\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "print(f\"Average Optimal Threshold: {average_opt_threshold}, Average F1 Score: {average_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf9bc39f418ec411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T00:45:46.918363Z",
     "start_time": "2024-02-21T00:45:44.405595Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     10658\n",
      "           1       0.93      0.67      0.78      1085\n",
      "\n",
      "    accuracy                           0.97     11743\n",
      "   macro avg       0.95      0.83      0.88     11743\n",
      "weighted avg       0.96      0.97      0.96     11743\n",
      "\n",
      "367/367 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     10658\n",
      "           1       0.93      0.67      0.78      1084\n",
      "\n",
      "    accuracy                           0.96     11742\n",
      "   macro avg       0.95      0.83      0.88     11742\n",
      "weighted avg       0.96      0.96      0.96     11742\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = (model.predict(X_val_scaled).ravel() >= average_opt_threshold).astype(int)\n",
    "print(classification_report(y_val, y_pred_prob))\n",
    "y_pred_prob = (model.predict(X_test_scaled).ravel() >= average_opt_threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018fad01dc1b433",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T07:43:11.058257Z",
     "start_time": "2024-02-21T01:36:00.833951Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    num_of_layers = trial.suggest_int('num_of_layers', 2, 6, step = 1)\n",
    "    dense_num_of_neurons = trial.suggest_int('num_of_neurons', 1, 6, step = 1)\n",
    "    dense_num_of_neurons = 2 ** dense_num_of_neurons\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.6)\n",
    "    l2 = trial.suggest_float('l2', 0.001, 1, log = True)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 1, log = True)\n",
    "    scale_pos_weight_multiplier = trial.suggest_int('scale_pos_weight_multiplier', 1, 4)\n",
    "    \n",
    "    model = DiabetesClassifier(X_train_scaled.shape[1], num_of_dense_layers =num_of_layers, dense_number =dense_num_of_neurons, dropout = dropout, l2 = l2)\n",
    "    tensorboard = keras.callbacks.TensorBoard(log_dir='logs')\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [metrics.AUC(), metrics.Precision(), metrics.Recall(), metrics.Accuracy()])\n",
    "    model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), batch_size =32, epochs = 20, class_weight = {1: scale_pos_weight/scale_pos_weight_multiplier, 0: 1}, callbacks = [tensorboard])\n",
    "\n",
    "    n_splits = 5  # Number of folds for StratifiedKFold\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    opt_thresholds = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for train_index, val_index in cv.split(combined_X_train, combined_y_train):\n",
    "        # Split data into training and validation for the current fold\n",
    "        X_train_curr, X_val_curr = combined_X_train[train_index], combined_X_train[val_index]\n",
    "        y_train_curr, y_val_curr = combined_y_train[train_index], combined_y_train[val_index]\n",
    "    \n",
    "        # Predict probabilities for the positive class on the validation data\n",
    "        y_pred_prob = model.predict(X_val_curr).ravel()\n",
    "    \n",
    "        # Compute precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_val_curr, y_pred_prob)\n",
    "    \n",
    "        # Calculate F1 scores for each threshold\n",
    "        f1_scores_fold = [2 * (p * r) / (p + r) if (p + r) > 0 else 0 for p, r in zip(precision, recall)]\n",
    "    \n",
    "        # Find the index of the maximum F1 score\n",
    "        opt_idx = np.argmax(f1_scores_fold)\n",
    "        opt_threshold = thresholds[opt_idx] if opt_idx < len(thresholds) else 1.0\n",
    "    \n",
    "        # Store the optimal threshold for this fold\n",
    "        opt_thresholds.append(opt_threshold)\n",
    "        f1_scores.append(f1_scores_fold[opt_idx])\n",
    "    \n",
    "        average_opt_threshold = np.mean(opt_thresholds)\n",
    "        average_f1_score = np.mean(f1_scores)\n",
    "        trial.set_user_attr('average_opt_threshold', average_opt_threshold)\n",
    "        return average_f1_score\n",
    "    \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best result: ', study.best_trial.value)\n",
    "print('Best trial:', study.best_trial.params)\n",
    "# To use the best parameters:\n",
    "best_params = study.best_trial.params\n",
    "best_threshold = study.best_trial.user_attrs['average_opt_threshold']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f70db62ec72a909c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T10:51:17.874960Z",
     "start_time": "2024-02-21T10:37:19.866583Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3109/3109 [==============================] - 44s 14ms/step - loss: 1.0195 - auc_22: 0.9162 - precision_22: 0.6719 - recall_22: 0.9767 - accuracy: 3.0160e-05 - val_loss: 0.9082 - val_auc_22: 0.9466 - val_precision_22: 0.1861 - val_recall_22: 0.9908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.8168 - auc_22: 0.9389 - precision_22: 0.6899 - recall_22: 0.9890 - accuracy: 2.2118e-04 - val_loss: 0.6336 - val_auc_22: 0.9459 - val_precision_22: 0.2354 - val_recall_22: 0.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.7756 - auc_22: 0.9420 - precision_22: 0.7000 - recall_22: 0.9906 - accuracy: 2.7144e-04 - val_loss: 0.8337 - val_auc_22: 0.9503 - val_precision_22: 0.2144 - val_recall_22: 0.9843 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "3109/3109 [==============================] - 43s 14ms/step - loss: 0.7463 - auc_22: 0.9439 - precision_22: 0.7122 - recall_22: 0.9914 - accuracy: 3.2171e-04 - val_loss: 0.8958 - val_auc_22: 0.9534 - val_precision_22: 0.2083 - val_recall_22: 0.9972 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.7255 - auc_22: 0.9440 - precision_22: 0.7184 - recall_22: 0.9929 - accuracy: 7.8417e-04 - val_loss: 0.7195 - val_auc_22: 0.9543 - val_precision_22: 0.2288 - val_recall_22: 0.9899 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.7113 - auc_22: 0.9453 - precision_22: 0.7213 - recall_22: 0.9937 - accuracy: 0.0034 - val_loss: 0.7014 - val_auc_22: 0.9525 - val_precision_22: 0.2376 - val_recall_22: 0.9917 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "3109/3109 [==============================] - 42s 13ms/step - loss: 0.7018 - auc_22: 0.9468 - precision_22: 0.7212 - recall_22: 0.9941 - accuracy: 0.0152 - val_loss: 0.9383 - val_auc_22: 0.9541 - val_precision_22: 0.2070 - val_recall_22: 0.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.6954 - auc_22: 0.9474 - precision_22: 0.7254 - recall_22: 0.9945 - accuracy: 0.0223 - val_loss: 0.7254 - val_auc_22: 0.9550 - val_precision_22: 0.2231 - val_recall_22: 0.9945 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "3109/3109 [==============================] - 42s 13ms/step - loss: 0.6877 - auc_22: 0.9489 - precision_22: 0.7272 - recall_22: 0.9943 - accuracy: 0.0253 - val_loss: 0.7543 - val_auc_22: 0.9544 - val_precision_22: 0.2238 - val_recall_22: 0.9917 - val_accuracy: 8.5157e-05\n",
      "Epoch 10/20\n",
      "3109/3109 [==============================] - 41s 13ms/step - loss: 0.6877 - auc_22: 0.9492 - precision_22: 0.7250 - recall_22: 0.9944 - accuracy: 0.0312 - val_loss: 0.8272 - val_auc_22: 0.9553 - val_precision_22: 0.2171 - val_recall_22: 0.9972 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "3109/3109 [==============================] - 42s 13ms/step - loss: 0.6820 - auc_22: 0.9498 - precision_22: 0.7276 - recall_22: 0.9948 - accuracy: 0.0320 - val_loss: 0.7423 - val_auc_22: 0.9551 - val_precision_22: 0.2325 - val_recall_22: 0.9899 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.6795 - auc_22: 0.9501 - precision_22: 0.7259 - recall_22: 0.9945 - accuracy: 0.0282 - val_loss: 0.7297 - val_auc_22: 0.9552 - val_precision_22: 0.2333 - val_recall_22: 0.9871 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "3109/3109 [==============================] - 42s 14ms/step - loss: 0.6816 - auc_22: 0.9498 - precision_22: 0.7240 - recall_22: 0.9952 - accuracy: 0.0262 - val_loss: 0.7239 - val_auc_22: 0.9544 - val_precision_22: 0.2192 - val_recall_22: 0.9954 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "3109/3109 [==============================] - 42s 13ms/step - loss: 0.6809 - auc_22: 0.9505 - precision_22: 0.7255 - recall_22: 0.9946 - accuracy: 0.0284 - val_loss: 0.7206 - val_auc_22: 0.9567 - val_precision_22: 0.2201 - val_recall_22: 0.9945 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9986b77130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DiabetesClassifier(X_train_scaled.shape[1], num_of_dense_layers =best_params['num_of_layers'], dense_number = 2 ** best_params['num_of_neurons'], dropout = best_params['dropout'], l2 = best_params['l2'])\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='logs')\n",
    "optimizer = keras.optimizers.Adam(learning_rate = best_params['learning_rate'])\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [metrics.AUC(), metrics.Precision(), metrics.Recall(), metrics.Accuracy()])\n",
    "model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), batch_size =32, epochs = 20, class_weight = {1: scale_pos_weight/best_params['scale_pos_weight_multiplier'], 0: 1}, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21db19c29c0ecab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T10:51:19.333327Z",
     "start_time": "2024-02-21T10:51:17.876031Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     10658\n",
      "           1       0.83      0.58      0.69      1085\n",
      "\n",
      "    accuracy                           0.95     11743\n",
      "   macro avg       0.90      0.78      0.83     11743\n",
      "weighted avg       0.95      0.95      0.95     11743\n",
      "\n",
      "367/367 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     10658\n",
      "           1       0.86      0.61      0.72      1084\n",
      "\n",
      "    accuracy                           0.96     11742\n",
      "   macro avg       0.91      0.80      0.85     11742\n",
      "weighted avg       0.95      0.96      0.95     11742\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = (model.predict(X_val_scaled).ravel() >= best_threshold).astype(int)\n",
    "print(classification_report(y_val, y_pred_prob))\n",
    "y_pred_prob = (model.predict(X_test_scaled).ravel() >= best_threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdbf591c6ded3d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T10:54:54.512058Z",
     "start_time": "2024-02-21T10:54:53.708153Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feffd99f6b7a07",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a converter object\n",
    "ae = tf.keras.models.load_model('model')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(ae)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # Enable TensorFlow ops.\n",
    "]\n",
    "# This example enables dynamic range quantization\n",
    "converter.allow_custom_ops = True  # Allow for the possibility of custom operations\n",
    "\n",
    "# Enable verbose logging\n",
    "converter.experimental_new_converter = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "# Perform the conversion\n",
    "tflite_model = converter.convert()\n",
    "# Replace 'converted_model.tflite' with the desired path for your .tflite model\n",
    "with open('converted_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
