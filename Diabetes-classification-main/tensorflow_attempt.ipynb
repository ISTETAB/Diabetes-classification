{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "Diabetes is a widespread and pressing health issue globally, affecting millions of people today. The goal of the project is to develop a machine learning model capable of predicting the likelihood of an individual developing diabetes based on relevant observed features including but limited to: gender, age, smoking and other relevant factors in our dataset. This project is relevant to the team’s interests as each one of us is working with similar machine learning medical-applications such as iris diseases recognition and classification and choosing a project as such creates a cohesive learning experience for the team. Moreover, other factors that were considered while choosing this problem was the availability of well-documented datasets that readily available and the significance of issue in the health domain as 422 million people today suffer from diabetes, that is 0.52% of the word’s population.\n",
    "\n",
    "## Dataset Selection and Description\n",
    "The chosen dataset for our model was carefully selected among multiple ones that were available. The selection focused on relevance of features in the dataset and the diversity of these features to encompass the most suitable range of features that also ensures a complexity challenging enough to reflect and apply our skills. Below is the detailed explanation of the data set used:\n",
    "\n",
    "## Features:\n",
    "1. **Gender:**\n",
    "   - Categorical variable representing the gender of the individual, i.e., males or females.\n",
    "\n",
    "2. **Age:**\n",
    "   - Continuous variable indicating the age of the individual (ranging from as high as 80 years to as low as 0.08 years old).\n",
    "\n",
    "3. **Hypertension:**\n",
    "   - A binary variable (0 or 1) that denotes the presence or absence of hypertension for the individuals.\n",
    "\n",
    "4. **Heart Disease:**\n",
    "   - Binary variable (0 or 1) indicating whether the individual has or does not have a history of a heart disease.\n",
    "\n",
    "5. **Smoking History:**\n",
    "   - Categorical variable that represents the smoking history of the individual, the three categories are (never, current, former).\n",
    "\n",
    "6. **BMI (Body Mass Index):**\n",
    "   - Continuous variable measuring the body mass index, it provides insights to the individual weight status.\n",
    "   - A BMI of 18.5 to 24.9 is considered to be healthy, anything above is considered overweight and anything below is underweight.\n",
    "\n",
    "7. **HBA1C Level:**\n",
    "   - Continuous variable representing the level of glycosylated hemoglobin, an important of indicator of diabetes management.\n",
    "   - Normal HBA1C values are considered to be below 5.7%, anyone with an HbA1c value of 5.7% to 6.4% is considered to be prediabetic, while diabetes can be diagnosed with a HbA1c of 6.5% or higher.\n",
    "\n",
    "8. **Blood Glucose Level:**\n",
    "   - Continuous variable denoting the blood glucose level, a very critical parameter in diabetes diagnosis.\n",
    "   - Expected values for normal fasting blood glucose level are between 70 mg/dl and 100 mg/dl. However, in our case, the data collected is not strictly meeting the fasting condition and so the common medical practice is to set the limit to 140 mg/dl for the highest normal range, and 200 mg/dl and above for concerning range, anything between is usually considered in the pre-diabetic phase.\n",
    "\n",
    "## Rationale for Dataset Selection:\n",
    "\n",
    "- **Feature diversity and relevance:**\n",
    "  - The dataset incorporates a wide array of different features that captures relative demographic (age, gender), medical history (heart diseases and hypertension), lifestyle choices (smoking) and relative health test metrics (BMI, HbA1c and blood glucose level).\n",
    "\n",
    "- **Real-World relevance:**\n",
    "  - Attributes are all considerably relevant to our test including important health metrics that are conventionally used in the medical field to make a diabetes diagnoses.\n",
    "\n",
    "- **Balanced Target Variable:**\n",
    "  - The dataset contains good balance in target variable distribution (Diabetes), preventing model bias and ensuring a more comprehensive outcome to our model.\n",
    "\n",
    "All in all, the selected dataset provides a rich but also challenging environment for developing a diabetes prediction model that encompasses a mass of features crucial for accurate and reliable predictions in the context of diabetes assessment.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c98cfb8618d1482"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T13:20:01.217067Z",
     "start_time": "2024-02-25T13:20:01.212041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "df = pd.read_csv('diabetes_prediction_dataset.csv')\n",
    "df = df[df['age']>=18]\n",
    "df = df[df['bmi']<=40]\n",
    "#Preprocess the data\n",
    "numeric_col=[]\n",
    "non_numeric_col=[]\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        if(df[column].nunique()<5):\n",
    "            non_numeric_col.append(column)\n",
    "        else:\n",
    "            numeric_col.append(column)\n",
    "    else:\n",
    "        non_numeric_col.append(column)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['smoking_history'] = df['smoking_history'].replace({'not current':'former','ever':'never'})\n",
    "df_copy = df.copy()\n",
    "for col in non_numeric_col:\n",
    "    df[col]=le.fit_transform(df[col])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T12:54:00.988914Z",
     "start_time": "2024-02-25T12:54:00.384443Z"
    }
   },
   "id": "55cb0f1640d0e79f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = df['diabetes']\n",
    "X = df.drop('diabetes', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T12:54:01.705811Z",
     "start_time": "2024-02-25T12:54:01.701644Z"
    }
   },
   "id": "cee8173b7a65bc95",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scale_pos_weight = y.value_counts()[0] /  y.value_counts()[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T12:54:03.184234Z",
     "start_time": "2024-02-25T12:54:03.179094Z"
    }
   },
   "id": "f0788172b85a6fa3",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, stratify = y_test)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "combined_X_train = np.concatenate((X_train_scaled,X_val_scaled), axis = 0)\n",
    "combined_y_train = np.concatenate((y_train,y_val), axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T13:11:03.906946Z",
     "start_time": "2024-02-25T13:11:03.881462Z"
    }
   },
   "id": "ae2d8dbae1b8ff36",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(99468, 8)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T13:00:30.207139Z",
     "start_time": "2024-02-25T13:00:30.203578Z"
    }
   },
   "id": "8270ef52602d7056",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Input\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable()\n",
    "class DiabetesClassifier(Model):\n",
    "    def __init__(self, data_input, num_of_dense_layers = 3, dense_number = 8, dropout = 0, l2 = 0.001, opt_threshold = 0):\n",
    "        super(DiabetesClassifier, self).__init__()\n",
    "        self.opt_threshold = opt_threshold\n",
    "        self.num_of_dense_layers = num_of_dense_layers\n",
    "        self.dense_number = dense_number\n",
    "        self.dropout = dropout\n",
    "        self.data_input = data_input\n",
    "        self.l2 = l2\n",
    "        self.model = self.build_model()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def build_model(self):\n",
    "        inp = Input(shape = self.data_input)\n",
    "        reg = keras.regularizers.l2(self.l2)\n",
    "        x = Dense(self.data_input, activation = 'relu', kernel_regularizer=reg)(inp)\n",
    "        for i in range(self.num_of_dense_layers):\n",
    "            x = Dense(units = self.dense_number, activation = 'relu', kernel_regularizer=reg)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(self.dropout)(x)\n",
    "        output = Dense(units =1, activation = 'sigmoid')(x)\n",
    "        model = Model(inputs = inp, outputs = output)\n",
    "        return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T12:54:08.971275Z",
     "start_time": "2024-02-25T12:54:08.967057Z"
    }
   },
   "id": "6823cc7e6d4ac4fe",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "import keras"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T12:54:11.120652Z",
     "start_time": "2024-02-25T12:54:11.118230Z"
    }
   },
   "id": "e818d4e5dcd36b77",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    num_of_layers = trial.suggest_int('num_of_layers', 2, 3, step = 1)\n",
    "    dense_num_of_neurons = trial.suggest_int('num_of_neurons', 5, 8, step = 1)\n",
    "    dense_num_of_neurons = 2 ** dense_num_of_neurons\n",
    "    dropout = trial.suggest_float('dropout', 0.2, 0.4)\n",
    "    l2 = trial.suggest_float('l2', 0.001, 0.01, log = True)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.01, log = True)\n",
    "    scale_pos_weight_multiplier = trial.suggest_int('scale_pos_weight_multiplier', 1, 3)\n",
    "    \n",
    "    model = DiabetesClassifier(X_train_scaled.shape[1], num_of_dense_layers =num_of_layers, dense_number =dense_num_of_neurons, dropout = dropout, l2 = l2)\n",
    "    tensorboard = keras.callbacks.TensorBoard(log_dir='logs')\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [metrics.AUC(), metrics.Precision(), metrics.Recall(), metrics.Accuracy()])\n",
    "    epochs = trial.suggest_int('epochs', 20,100, step = 10)\n",
    "    model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), batch_size =4092, epochs = 20, class_weight = {1: scale_pos_weight/scale_pos_weight_multiplier, 0: 1}, callbacks = [tensorboard])\n",
    "\n",
    "    n_splits = 5  # Number of folds for StratifiedKFold\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    opt_thresholds = []\n",
    "    f1_scores = []\n",
    "    recall_lis = []\n",
    "    precision_lis = []\n",
    "    # Choose the beta value you want.\n",
    "    beta = 1.45    \n",
    "    for train_index, val_index in cv.split(combined_X_train, combined_y_train):\n",
    "        # Split data into training and validation for the current fold\n",
    "        X_train_curr, X_val_curr = combined_X_train[train_index], combined_X_train[val_index]\n",
    "        y_train_curr, y_val_curr = combined_y_train[train_index], combined_y_train[val_index]\n",
    "        # Predict probabilities for the positive class on the validation data\n",
    "        y_pred_prob = model.predict(X_val_curr).ravel()\n",
    "    \n",
    "        # Compute precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_val_curr, y_pred_prob)\n",
    "    \n",
    "        # Calculate F1 scores for each threshold\n",
    "        # f1_scores_fold = [2 * (p * r) / (p + r) if (p + r) > 0 else 0 for p, r in zip(precision, recall)]\n",
    "        f1_scores_fold = [(1 + beta**2) * (prec * rec) / ((beta**2 * prec) + rec) for prec, rec in zip(precision, recall)]\n",
    "\n",
    "    # Find the index of the maximum F1 score\n",
    "        opt_idx = np.argmax(f1_scores_fold)\n",
    "        opt_threshold = thresholds[opt_idx] if opt_idx < len(thresholds) else 1.0\n",
    "        \n",
    "        # Store the optimal threshold for this fold\n",
    "        opt_thresholds.append(opt_threshold)\n",
    "        f1_scores.append(f1_scores_fold[opt_idx])\n",
    "        y_pred = (y_pred_prob > opt_threshold).astype(int)\n",
    "        recall_lis.append(recall_score(y_val_curr, y_pred))\n",
    "        precision_lis.append(precision_score(y_val_curr, y_pred))\n",
    "    \n",
    "    average_opt_threshold = np.mean(opt_thresholds)\n",
    "    average_f1_score = np.mean(f1_scores)\n",
    "    trial.set_user_attr('average_opt_threshold', average_opt_threshold)\n",
    "    trial.set_user_attr('Recall', np.mean(recall_lis))\n",
    "    trial.set_user_attr('Precision', np.mean(precision_lis))\n",
    "    return average_f1_score\n",
    "    \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best result: ', study.best_trial.value)\n",
    "print('Best trial:', study.best_trial.params)\n",
    "# To use the best parameters:\n",
    "best_params = study.best_trial.params\n",
    "best_threshold = study.best_trial.user_attrs['average_opt_threshold']\n",
    "df = study.trials_dataframe()\n",
    "# Save to a CSV file for further analysis\n",
    "df.to_csv(\"optuna_trials.csv\", index=False, mode = 'a')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8018fad01dc1b433",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extracted the best params from the CSV file\n",
    "dropout, l2, learning_rate, num_of_layers, num_of_neurons, scale_pos_weight_multiplier = 0.283041005,\t0.002680608,\t0.001094543,\t3,\t7,\t2\n",
    "best_params = {'dropout':dropout, 'l2': l2, 'learning_rate':learning_rate,'num_of_layers': num_of_layers, 'num_of_neurons':num_of_neurons, 'scale_pos_weight_multiplier':scale_pos_weight_multiplier}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T13:07:09.183552Z",
     "start_time": "2024-02-25T13:07:09.181068Z"
    }
   },
   "id": "8f64033385afbdf1",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = DiabetesClassifier(X_train_scaled.shape[1], num_of_dense_layers =best_params['num_of_layers'], dense_number = 2 ** best_params['num_of_neurons'], dropout = best_params['dropout'], l2 = best_params['l2'])\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='logs')\n",
    "optimizer = keras.optimizers.Adam(learning_rate = best_params['learning_rate'])\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = [metrics.AUC(), metrics.Precision(), metrics.Recall(), metrics.Accuracy()])\n",
    "model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), batch_size =4092, epochs = 80, class_weight = {1: scale_pos_weight/best_params['scale_pos_weight_multiplier'], 0: 1}, callbacks = [tensorboard])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f70db62ec72a909c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/416 [==============================] - 1s 2ms/step\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "416/416 [==============================] - 1s 2ms/step\n",
      "Fold 1: Optimal threshold: 0.5391228199005127, F1 Score: 0.7596661028649636\n",
      "Fold 2: Optimal threshold: 0.5223883390426636, F1 Score: 0.7383446393231858\n",
      "Fold 3: Optimal threshold: 0.5060943961143494, F1 Score: 0.7415705021453342\n",
      "Fold 4: Optimal threshold: 0.5399326086044312, F1 Score: 0.7735631880635606\n",
      "Fold 5: Optimal threshold: 0.5187482833862305, F1 Score: 0.7567127746135069\n",
      "Average Optimal Threshold: 0.5252572894096375, Average F1 Score: 0.7539714414021101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "n_splits = 5  # Number of folds for StratifiedKFold\n",
    "beta= 1.45\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "opt_thresholds = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in cv.split(combined_X_train, combined_y_train):\n",
    "    # Split data into training and validation for the current fold\n",
    "    X_train_curr, X_val_curr = combined_X_train[train_index], combined_X_train[val_index]\n",
    "    y_train_curr, y_val_curr = combined_y_train[train_index], combined_y_train[val_index]\n",
    "\n",
    "    # Predict probabilities for the positive class on the validation data\n",
    "    y_pred_prob = model.predict(X_val_curr).ravel()\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val_curr, y_pred_prob)\n",
    "\n",
    "    # Calculate F1 scores for each threshold\n",
    "    # f1_scores_fold = [2 * (p * r) / (p + r) if (p + r) > 0 else 0 for p, r in zip(precision, recall)]\n",
    "    f1_scores_fold = [(1 + beta**2) * (prec * rec) / ((beta**2 * prec) + rec) for prec, rec in zip(precision, recall)]\n",
    "\n",
    "    # Find the index of the maximum F1 score\n",
    "    opt_idx = np.argmax(f1_scores_fold)\n",
    "    opt_threshold = thresholds[opt_idx] if opt_idx < len(thresholds) else 1.0\n",
    "\n",
    "    # Store the optimal threshold for this fold\n",
    "    opt_thresholds.append(opt_threshold)\n",
    "    f1_scores.append(f1_scores_fold[opt_idx])\n",
    "\n",
    "# Optionally, you can print or analyze the optimal thresholds and F1 scores for each fold\n",
    "for i, (threshold, f1_score) in enumerate(zip(opt_thresholds, f1_scores)):\n",
    "    print(f\"Fold {i+1}: Optimal threshold: {threshold}, F1 Score: {f1_score}\")\n",
    "\n",
    "# You might also calculate and print the average optimal threshold and F1 score across folds if desired\n",
    "average_opt_threshold = np.mean(opt_thresholds)\n",
    "average_f1_score = np.mean(f1_scores)\n",
    "print(f\"Average Optimal Threshold: {average_opt_threshold}, Average F1 Score: {average_f1_score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T13:11:36.829380Z",
     "start_time": "2024-02-25T13:11:31.849596Z"
    }
   },
   "id": "b31a75cd65f0506b",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     10658\n",
      "           1       0.77      0.75      0.76      1085\n",
      "\n",
      "    accuracy                           0.96     11743\n",
      "   macro avg       0.87      0.86      0.87     11743\n",
      "weighted avg       0.96      0.96      0.96     11743\n",
      "367/367 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     10658\n",
      "           1       0.74      0.73      0.74      1084\n",
      "\n",
      "    accuracy                           0.95     11742\n",
      "   macro avg       0.86      0.85      0.85     11742\n",
      "weighted avg       0.95      0.95      0.95     11742\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = (model.predict(X_val_scaled) > average_opt_threshold).astype(int)\n",
    "print(classification_report(y_val, y_pred_prob))\n",
    "y_pred_prob = (model.predict(X_test_scaled).ravel() >= average_opt_threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred_prob))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T13:11:38.416446Z",
     "start_time": "2024-02-25T13:11:36.830387Z"
    }
   },
   "id": "21db19c29c0ecab8",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T00:15:55.584037Z",
     "start_time": "2024-02-23T00:15:54.697064Z"
    }
   },
   "id": "cdbf591c6ded3d29",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf4066eal/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpf4066eal/assets\n",
      "2024-02-23 02:15:57.231097: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-23 02:15:57.231125: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-23 02:15:57.231388: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpf4066eal\n",
      "2024-02-23 02:15:57.232453: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-23 02:15:57.232461: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpf4066eal\n",
      "2024-02-23 02:15:57.235180: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-02-23 02:15:57.236013: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-23 02:15:57.258547: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpf4066eal\n",
      "2024-02-23 02:15:57.266933: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 35532 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 19, % non-converted = 36.84 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 7)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n"
     ]
    }
   ],
   "source": [
    "# Create a converter object\n",
    "ae = tf.keras.models.load_model('model')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(ae)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # Enable TensorFlow ops.\n",
    "]\n",
    "# This example enables dynamic range quantization\n",
    "converter.allow_custom_ops = True  # Allow for the possibility of custom operations\n",
    "\n",
    "# Enable verbose logging\n",
    "converter.experimental_new_converter = True\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "# Perform the conversion\n",
    "tflite_model = converter.convert()\n",
    "# Replace 'converted_model.tflite' with the desired path for your .tflite model\n",
    "with open('converted_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T00:15:57.362840Z",
     "start_time": "2024-02-23T00:15:55.585272Z"
    }
   },
   "id": "72feffd99f6b7a07",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
